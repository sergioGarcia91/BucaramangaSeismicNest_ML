{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergioGarcia91/BucaramangaSeismicNest_ML/blob/main/ML_SismosNido_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRcbyPtdH6xE"
      },
      "source": [
        "This notebook was created as part of the revision process to apply SHAP (https://shap.readthedocs.io) for interpreting the contribution of input features in neural network models, specifically using scikit-learn's `MLPClassifier`.\n",
        "\n",
        "https://shap.readthedocs.io/en/stable/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aclniN9IEez"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeLvb5ZOIVCc",
        "outputId": "d3bc95de-b1cb-40eb-935a-0f10a4f1bdf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnGWnIPOJUcC",
        "outputId": "ce9a3146-68af-4909-c4db-1939360fe1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.61.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eAuAWpKzIZOz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import shap\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier # Para la Red Neuronal\n",
        "from joblib import dump, load # guardar el modelo\n",
        "from datetime import datetime, timedelta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIJKt350IjZM"
      },
      "outputs": [],
      "source": [
        "pathDatos = '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/Catalogos/'\n",
        "pathSaveFiguras = '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/Figuras_shap/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9kvFhSnP_BC"
      },
      "source": [
        "# Change the font type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XKPgKEgVP-lx"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.font_manager as fm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9jsA9OMXV5a",
        "outputId": "593dbc74-5a4a-4c22-c581-3b8bfed363b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-01 13:30:45--  https://github.com/justrajdeep/fonts/raw/master/Times%20New%20Roman.ttf\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/justrajdeep/fonts/master/Times%20New%20Roman.ttf [following]\n",
            "--2025-07-01 13:30:45--  https://raw.githubusercontent.com/justrajdeep/fonts/master/Times%20New%20Roman.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 834452 (815K) [application/octet-stream]\n",
            "Saving to: ‘Times New Roman.ttf.3’\n",
            "\n",
            "Times New Roman.ttf 100%[===================>] 814.89K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-01 13:30:45 (13.6 MB/s) - ‘Times New Roman.ttf.3’ saved [834452/834452]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/justrajdeep/fonts/raw/master/Times%20New%20Roman.ttf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-m2VqdhZYthZ",
        "outputId": "aeca76a1-7e1f-4f04-b6c5-20998b77828f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Times New Roman'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Ruta a la fuente personalizada\n",
        "font_path = 'Times New Roman.ttf'\n",
        "\n",
        "# Añadir la fuente al administrador de fuentes de Matplotlib\n",
        "font_prop = fm.FontProperties(fname=font_path)\n",
        "fm.fontManager.addfont(font_path)\n",
        "\n",
        "# Nombre de la fuente para usar en rcParams\n",
        "font_name = font_prop.get_name()\n",
        "font_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzt7HpslJBXr"
      },
      "source": [
        "# SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "q29zOaBrFkOD"
      },
      "outputs": [],
      "source": [
        "# best 10 AUC\n",
        "ordenModelos = ['/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v6/2009_30dias_boots_hl_420_210_105_53_27_5_int0_scr0.997.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v4/2009_30dias_hl_420_5_int0_scr0.998.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v4/2009_30dias_hl_2000_5_int1_scr1.0.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v4/2009_6meses_hl_210_5_int0_scr1.0.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v6/2009_30dias_boots_hl_1500_5_int0_scr1.0.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v6/2009_30dias_boots_hl_420_5_int0_scr1.0.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v4/2009_30dias_hl_1500_5_int0_scr1.0.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v6/2009_6meses_hl_1500_750_375_188_94_5_int0_scr0.996.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v6/2009_30dias_boots_hl_2000_5_int0_scr0.999.joblib',\n",
        "                '/content/drive/MyDrive/Manuscritos_Investigacion/ML_SismosNidoBucaramanga/ModelosMLP_Class_v6/2009_6meses_hl_210_105_53_27_13_5_int0_scr1.0.joblib']\n",
        "\n",
        "# label\n",
        "labelModel = ['Mod 7',\n",
        "              'Mod 15',\n",
        "              'Mod 32',\n",
        "              'Mod 41',\n",
        "              'Mod 26',\n",
        "              'Mod 13',\n",
        "              'Mod 47',\n",
        "              'Mod 12',\n",
        "              'Mod 25',\n",
        "              'Mod 24']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PmITvAXJciJ"
      },
      "source": [
        "A subset of 200 training samples will be used for each model to evaluate the influence of the input features, along with 100 test samples. Both datasets are balanced, with half of the instances belonging to class 0 and the other half to class 1.\n",
        "\n",
        "Reference examples:\n",
        "\n",
        "https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Diabetes%20regression.html\n",
        "\n",
        "\n",
        "https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Iris%20classification%20with%20scikit-learn.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYDwYdP_KaWi"
      },
      "outputs": [],
      "source": [
        "inicial_model = 8\n",
        "\n",
        "for modelo, labelModelo in zip(ordenModelos[inicial_model:], labelModel[inicial_model:]):\n",
        "  if 'joblib' in modelo:\n",
        "    if '6meses' in modelo:\n",
        "      dias_Considerar = 180\n",
        "      X2023 = np.loadtxt(pathDatos+'2009_6meses_X2022.txt')\n",
        "      y2023 = np.loadtxt(pathDatos+'2009_6meses_y2022.txt')\n",
        "      X2022 = np.loadtxt(pathDatos+'2009_6meses_X2021.txt')\n",
        "      y2022 = np.loadtxt(pathDatos+'2009_6meses_y2021.txt')\n",
        "\n",
        "    if '12meses' in modelo:\n",
        "      dias_Considerar = 365\n",
        "      X2023 = np.loadtxt(pathDatos+'2009_12meses_X2022.txt')\n",
        "      y2023 = np.loadtxt(pathDatos+'2009_12meses_y2022.txt')\n",
        "      X2022 = np.loadtxt(pathDatos+'2009_12meses_X2021.txt')\n",
        "      y2022 = np.loadtxt(pathDatos+'2009_12meses_y2021.txt')\n",
        "\n",
        "    if '30dias' in modelo:\n",
        "      dias_Considerar = 30\n",
        "      X2023 = np.loadtxt(pathDatos+'2009_30dias_X2022.txt')\n",
        "      y2023 = np.loadtxt(pathDatos+'2009_30dias_y2022.txt')\n",
        "      X2022 = np.loadtxt(pathDatos+'2009_30dias_X2021.txt')\n",
        "      y2022 = np.loadtxt(pathDatos+'2009_30dias_y2021.txt')\n",
        "\n",
        "    print(10*'---')\n",
        "    print(labelModelo)\n",
        "    print('Train shape: ', X2022.shape)\n",
        "    print('Test shape: ', X2023.shape)\n",
        "    print('Y test sum: ', y2023.sum())\n",
        "\n",
        "    # labels days\n",
        "    days_labels = []\n",
        "    days = int(X2022.shape[1]/7)\n",
        "    print(days)\n",
        "    for day in range(days-1, -1, -1):\n",
        "      for ml in ['2.5-3.0', '3.0-3.5', '3.5-4.0', '4.0-4.5', '4.5-5.0', '5.0-5.5', '>=5.5']:\n",
        "        label = f'-{day}D Ml[{ml}]'\n",
        "        days_labels.append(label)\n",
        "    print(days_labels)\n",
        "    print(len(days_labels)==X2022.shape[1])\n",
        "\n",
        "\n",
        "    modelo_P = load(modelo)\n",
        "    n_features = X2022.shape[1]\n",
        "\n",
        "    # 2023\n",
        "    #predichosModelo = modelo_P.predict(X2023)\n",
        "    #predProb_Modelo = modelo_P.predict_proba(X2023)[:,1]\n",
        "    # 1994-2023\n",
        "    #predichosModelo_2022 = modelo_P.predict(X2022)\n",
        "    #predProb_Modelo_2022 = modelo_P.predict_proba(X2022)[:,1]\n",
        "\n",
        "    #nMin = dias_Considerar - 1\n",
        "\n",
        "\n",
        "    #reducir las muestras a solo 200 TRAIN\n",
        "    samples = int(200 / 2) # la mitad va ser 0 y la otra 1 # 80 mod 12 24\n",
        "    filter_0 = y2022 == 0\n",
        "    filter_1 = y2022 == 1\n",
        "    X2022_0 = X2022[filter_0, :].copy()\n",
        "    X2022_1 = X2022[filter_1, :].copy()\n",
        "\n",
        "    increse = int(X2022_0.shape[0]/samples)\n",
        "    X2022_0 = X2022_0[::increse, :]\n",
        "    X2022_0 = X2022_0[:samples, :]\n",
        "    increse = int(X2022_1.shape[0]/samples)\n",
        "    X2022_1 = X2022_1[::increse, :]\n",
        "    X2022_1 = X2022_1[:samples, :]\n",
        "    X2022 = np.concatenate((X2022_0, X2022_1), axis=0)\n",
        "    print('New shape Train: ', X2022.shape)\n",
        "\n",
        "    #reducir las muestras a solo 100 TEST\n",
        "    samples = int(100 / 2 ) # 30 para el mod 12 24\n",
        "    filter_0 = y2023 == 0\n",
        "    filter_1 = y2023 == 1\n",
        "    X2023_0 = X2023[filter_0, :].copy()\n",
        "    X2023_1 = X2023[filter_1, :].copy()\n",
        "\n",
        "    increse = int(X2023_0.shape[0]/samples)\n",
        "    X2023_0 = X2023_0[::increse, :]\n",
        "    X2023_0 = X2023_0[:samples, :]\n",
        "    increse = int(X2023_1.shape[0]/samples)\n",
        "    X2023_1 = X2023_1[::increse, :]\n",
        "    X2023_1 = X2023_1[:samples, :]\n",
        "    X2023 = np.concatenate((X2023_0, X2023_1), axis=0)\n",
        "    print('New shape Test: ', X2023.shape)\n",
        "\n",
        "\n",
        "\n",
        "    # Crear el explainer de SHAP\n",
        "    explainer = shap.KernelExplainer(modelo_P.predict_proba, # Modelo o funcion que predice\n",
        "                                     X2022,# Los datos de fondo que se usaran para reemplazar en la explicacion\n",
        "                                     feature_names=days_labels) # Las etiquetas de las features\n",
        "\n",
        "    #shap_values = explainer.shap_values(X2023)\n",
        "    shap_values = explainer(X2023) # Para poder hacer el de barras\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5, 8))\n",
        "    # Graficar SHAP\n",
        "    shap.plots.bar(shap_values[:, :, 1], max_display=41, ax=ax, show=False)\n",
        "    # Título del gráfico\n",
        "    ax.set_title(f'{labelModelo} - Total features {n_features}', fontsize=12, fontname='Times New Roman')\n",
        "    # Cambiar fuente de las etiquetas de los ejes X e Y\n",
        "    for label in ax.get_xticklabels():\n",
        "        label.set_fontname('Times New Roman')\n",
        "        label.set_fontsize(10)\n",
        "    for label in ax.get_yticklabels():\n",
        "        label.set_fontname('Times New Roman')\n",
        "        label.set_fontsize(10)\n",
        "    # Ajustar el label del eje X\n",
        "    ax.set_xlabel(ax.get_xlabel(), fontsize=10, fontname='Times New Roman')\n",
        "    plt.tight_layout()\n",
        "    # Guardar la figura\n",
        "    plt.savefig((pathSaveFiguras + f'SHAP_{labelModelo}.png'),\n",
        "                format='png', dpi=1000, bbox_inches = 'tight',pad_inches=0.25)\n",
        "\n",
        "    plt.show()\n",
        "    print(10*'---')\n",
        "    print(10*'---')\n",
        "    print('\\n') #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuvCtc8lICwM"
      },
      "source": [
        "# End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TPcowzc5IC_U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO0ykt3n5VHoqB3p55JL64g",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}